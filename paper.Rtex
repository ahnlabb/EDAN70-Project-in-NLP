\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2018}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

% review option: For printing line numbers:
%\documentclass[sigplan,10pt,review]{acmart} 

\settopmatter{printfolios=true,printccs=false,printacmref=false}
%printfolios=true, means print page numbers
%printccs=false, means don't show CCS categories
%printacmref=false, means don't show acm reference


\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\}

\setcopyright{none}

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}

\usepackage{lipsum}
\usepackage[acronym]{glossaries}
\usepackage{booktabs}

\makeglossaries

\begin{document}

\newacronym{edl}{EDL}{Entity Discovery and Linking}
\newacronym{ner}{NER}{Named Entity Recognition}
\newacronym{el}{EL}{Entity Linking}
\newacronym{bilstm}{BiLSTM}{Bidirectional Long Short-Term Memory}
\newacronym{lstm}{LSTM}{Long Short-Term Memory}
\newacronym{crf}{CRF}{Conditional Random Fields}
\newacronym{oov}{OOV}{Out of Vocabulary}
\newacronym{pos}{POS}{Part of Speech}
\newacronym{gui}{GUI}{Graphical User Interface}
\newacronym{tedl}{TEDL}{Trilingual Entity Discovery and Linking}
\newacronym{tac}{TAC}{Text Analysis Conference}
\newacronym{kbp}{KBP}{Knowledge Base Population}

\newcommand{\namper}{NAM-PER}
\newcommand{\nomper}{NOM-PER}
\newcommand{\linking}{strong typed all match}
\newcommand{\mention}{strong typed mention match}

%% Title information
\title{Entity Recognition and Linking}         %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
%\subtitle{Subtitle}                     %% \subtitle is optional


%% Author information
%% Each author should be introduced by \author, followed by
%% \affiliation, and \email.

%% Author with single affiliation.
\author{Johannes Ahnlide}
\affiliation{
  \institution{F13, Lund University, Sweden}            %% \institution is required
}
\email{tfy13jah@student.lu.se}          %% \email is recommended

\author{Dwight Lidman}
\affiliation{
  \institution{D13, Lund University, Sweden}            %% \institution is required
}
\email{dat13dli@student.lu.se}          %% \email is recommended


\begin{abstract}
Text of abstract \ldots.
\end{abstract}


\maketitle


\section{Introduction}

%Entity discovery and linking
\acrfull{edl} is the process of finding mentions of entities in a text and linking these entities to the corresponding entry in a knowledge base. \acrfull{ner} and \acrfull{el} are the primary constituent steps of this process and in this paper we will describe the mechanisms by which our system performs these steps, both as separate processes and as a unified process (EDL).

In this project we attempt to reproduce the results achieved by Yang et al.~\citep{YangThe2017} using the methods outlined in their paper.
% TODO: The following sentence was commented out because we haven't had time to extend
%The goal is to investigate whether the results are reproducible and additionally to potentially add support for other languages, seeking similar performance.
Those results were submitted to the \acrfull{tedl} track at \acrfull{tac} 2017. %\acrfull{kbp} % TODO

Our course of action for developing this system has been to iteratively reproduce the parts of the model from \cite{YangThe2017}, evaluating the model and adding features in each step of the iteration.

We implemented the majority of our system in python using Keras to develop the neural network. \cite{Francois2015Keras}

%\textit{Something about reproducing the model in iterative steps, comparing the performance as more features and layers are added?}

\section{Mention Detection}
As a first step in our iteration we leverage readily existing features from GloVe and CoreNLP to evaluate baseline performance in a basic reconstruction of the network described in \cite{YangThe2017}. The GloVe dataset provides our model with pre-trained word embeddings and CoreNLP provides us with basic \acrshort{ner} and \acrfull{pos} tagging.

In future iterations we intend to add character embeddings, as described in \cite{Lample2016NeuralRecognition}, to compensate for \acrfull{oov} issues.

\subsection{Features}
\subsubsection*{Word form}
Based on term frequency in our data set, we rank word forms and include only the most frequent ones in order to reduce noise arising from infrequent terms.
We then match each word with its corresponding GloVe vector while replacing \acrshort{oov} instances with a specific \acrshort{oov} vector.
\subsubsection*{Part of speech}
Using CoreNLP, we predict \acrshort{pos} tags and use these predictions as features.
\subsubsection*{Preemptive entity type}
In a similar manner, we use CoreNLP to detect entity boundaries and a preemptive entity type and use these as features.
\subsubsection*{Capitalization signifier}
In English and Spanish, the first letter in a name is capitalized. Furthermore, acronyms of organizations and the like are often written in uppercase. For that reason, we use a boolean signifier which is true if the word contains an uppercase letter and use that boolean value as a feature.
\subsubsection*{Special tokens}
We include a separate feature for "special" tokens in English, like prepositions and possessive signifiers -- as well as often recurring words like \textit{president}, which are either instances of \nomper{} or part of an instance of \namper{} -- in order to give greater weight to these tokens during training.

\subsection{Network Architecture}
%TODO refer to figure
Figure~\ref{fig:neural_net}
We use the terms \textit{input layer}, \textit{representative layer} and \textit{output layer} to help give a high-level description of our architecture.

The input layer consists of three trainable embeddings representing the word form, the \acrshort{pos} and the named entity type. In addition to the embeddings, two untrainable input layers representing word capitalization and special tokens, respectively.
The embeddings are concatenated with the untrainable input layers and fed into the representative layer.

The model is centered around the representative layer which consists two consecutive \acrfull{bilstm} layers.
The concatenated input is routed through a dropout layer with a dropout rate of 0.25 which in turn feeds into the \acrshort{bilstm} layers.
The output from the first \acrshort{bilstm} layer and the output from the previously mentioned dropout layer is concatenated to form the input for the second \acrshort{bilstm} layer.
To speed up training we used CuDNNLSTM, available in Keras, as the implementation of the \acrshort{bilstm}s. We chose the output dimensionality of each \acrshort{bilstm} to be 100. 

Our output layer consists of a simple dense layer which receives the concatenated output from the representative layer and is activated by a softmax function.

<< neural_net, engine = "dot", fig.lp="fig:", fig.cap = "A high-level representation of our implemented neural network.", cache=TRUE, echo=FALSE >>=
digraph G {
concentrate=True;
rankdir=TB;
node [shape=record];
140648102684096 [label="Form: Input"];
140648102683032 [label="POS: Input"];
140648179719976 [label="NE: Input"];
140648102685328 [label="Embedding"];
140648102684432 [label="Embedding"];
140648179720032 [label="Embedding"];
140648245566880 [label="Capital: Input"];
140648102684264 [label="Special: Input"];
140648102684376 [label="Concatenate"];
140648093942784 [label="Dropout"];
140648093678000 [label="Bidirectional(CuDNNLSTM)"];
140648094104656 [label="Concatenate"];
140647917305696 [label="Bidirectional(CuDNNLSTM)"];
140647916844200 [label="Dense"];
140648102684096 -> 140648102685328;
140648102683032 -> 140648102684432;
140648179719976 -> 140648179720032;
140648102685328 -> 140648102684376;
140648102684432 -> 140648102684376;
140648179720032 -> 140648102684376;
140648245566880 -> 140648102684376;
140648102684264 -> 140648102684376;
140648102684376 -> 140648093942784;
140648093942784 -> 140648093678000;
140648093942784 -> 140648094104656;
140648093678000 -> 140648094104656;
140648094104656 -> 140647917305696;
140647917305696 -> 140647916844200;
}
@

%\begin{figure}
    %\centering
    %\includegraphics[width=0.5\textwidth]{neural_net2.png}
    %\caption{A high-level representation of our implemented neural network.}
    %\label{fig:neural_net}
%\end{figure}

\subsection{Training}
We trained the model on data from the \acrshort{tedl} task from previous years (2015 and 2016) and used early stopping to prevent overfitting.

\subsection{XML Data}
The TAC Dataset includes some annotated structured data. The \texttt{author} attributes of XML \texttt{<post>} tags is an example and they are marked as names of persons (\namper{}). To catch these we added a simple regular expression.
\section{Entity Linking}

We created a mapping from words to Wikipedia pages by iterating over all anchors in all Wikipedia pages in the respective languages. For all anchors with the same text the most frequent target page was selected as the target entity in the dictionary.
Due to the size of Wikipedia we used Apache Spark to perform the processing and wrote that part of the code in Scala to maximize performance on Spark. In the implementation we also used Docria which implements an input specification for Map-Reduce jobs.\cite{Zaharia2016ApacheSpark}\cite{Klang2018Docria}

%\subsection{Candidate Generation}

%\subsection{Candidate Ranking}

\section{Evaluation}
We evaluated the system's performance by applying the neleval \texttt{tac2016} evaluation script on our system output and the tac2017 gold standard. %TODO: ref?
The results of this evaluation for some chosen metrics are presented in tables~\ref{tab:mention} and~\ref{tab:linkning}.

\begin{table}[]
    \centering
    \begin{tabular}{lrrr}
    \toprule
    Language &  Precision &  Recall &     F1 \\
    \midrule
     All &      0.844 &   0.586 &  0.692 \\
     ENG &      0.832 &   0.689 &  0.754 \\
     SPA &      0.864 &   0.564 &  0.682 \\
     CMN &      0.832 &   0.529 &  0.647 \\
    \bottomrule
    \end{tabular}
    \caption{The mention detection (\mention) results from running the neleval script on the output from our system.}
    \label{tab:mention}
\end{table}

\begin{table}[]
    \centering
    \begin{tabular}{lrrr}
    \toprule
    Language &  Precision &  Recall &     F1 \\
    \midrule
     All &      0.602 &   0.418 &  0.494 \\
     ENG &      0.551 &   0.456 &  0.499 \\
     SPA &      0.666 &   0.434 &  0.526 \\
     CMN &      0.596 &   0.379 &  0.463 \\
    \bottomrule
    \end{tabular}
    \caption{The linking (\linking) results from running the neleval script on the output from our system.}
    \label{tab:linkning}
\end{table}

PLOT PLOT PLOT

In plots %TODO
we have plotted our own results as well as the results of all the systems that participated in the \acrshort{tedl} task at TAC-KBP 2017.
As can be seen in these plots, our system is relatively performant compared to the other entries.

\section{Graphical User Interface}
\begin{figure*}
    \centering
    \includegraphics{news_ui3.png}
    \caption{The web based \acrshort{gui} showing the result of running the network on the description of a news article acquired from \href{https://newsapi.org}{newsapi.org}.}
    \label{fig:my_label}
\end{figure*}

We developed a web based \acrfull{gui} using Flask for the backend and \href{https://elm-lang.org}{elm} for the frontend. The \acrshort{gui} fetches descriptions of news articles and feeds them to the network and entity linker. Each entity that was successfully linked becomes a link to Wikipedia. When the user hovers over such an entity a summary is shown including its Wikidata label, an image and a short description. 
The news information is fetched from \href{https://newsapi.org}{newsapi.org} and the summary data is acquired using the Wikidata SPARQL Query Service.
\section{Future work}
\subsection{Mention Detection}
In the future we intend to replace our dense output layer with a \acrfull{crf} layer as per \citep{YangThe2017} because we expect it to yield significant performance increases in in mention detection and type classification.
For Chinese we currently use CoreNLP for word segmentation but this might introduce errors since there are no word delimiters in Chinese. One way to avoid this problem is to only work with the character sequence. When we attempted this it decreased the performance of our system. However, we did not add the CoreNLP word boundaries as a feature as was done by Yang et al. \citep{YangThe2017}. % TODO
In order to speed up training while simultaneously reducing the network's dependence on external tools and giving us greater control over our embeddings we intend to pre-train a separate network to replace the features for which we currently depend on CoreNLP.

\subsection{Entity Linking}
%The TAI system %TODO: Normalize references to this
Yang et al. \citep{YangThe2017}
used LambdaMART ranking with several handcrafted features such as number of languages on Wikipedia and a metric based on PageRank on Wikipedia to achieve better linking. We would like to implement this kind of ranking and at least a few of these features.

\section{Related work}

\section{Conclusion}
Reproducing the performance in the system built by \cite{YangThe2017} proved to be a difficult task in part due to critical details being left out of the paper, not having access to the same training data, as well as our relative inexperience working with machine learning models.
Given these difficulties we still managed to achieve high performance 

%% Acknowledgments
\begin{acks}
We would like to thank Pierre Nugues and Marcus Klang for their guidance and support throughout the project.
A special thanks to Marcus for creating Docria and providing us with the data we needed in accessible formats.
%TODO: Improve
\end{acks}


%% Bibliography
\bibliography{references}



\end{document}
