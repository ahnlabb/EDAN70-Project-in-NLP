\documentclass[sigplan,10pt]{acmart}

% review option: For printing line numbers:
%\documentclass[sigplan,10pt,review]{acmart} 

\settopmatter{printfolios=true,printccs=false,printacmref=false}
%printfolios=true, means print page numbers
%printccs=false, means don't show CCS categories
%printacmref=false, means don't show acm reference


\acmConference[Course paper, EDAN70]{Project in computer science}{Lund University}{Sweden}
\acmYear{\today}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

\setcopyright{none}

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}

\usepackage{lipsum}
\usepackage[acronym]{glossaries}

\makeglossaries

\begin{document}

\newacronym{edl}{EDL}{Entity Discovery and Linking}

%% Title information
\title[Short Title]{Full Title}         %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
%\subtitle{Subtitle}                     %% \subtitle is optional


%% Author information
%% Each author should be introduced by \author, followed by
%% \affiliation, and \email.

%% Author with single affiliation.
\author{Johannes Ahnlide}
\affiliation{
  \institution{F13, Lund University, Sweden}            %% \institution is required
}
\email{tfy13jah@student.lu.se}          %% \email is recommended

\author{Dwight Lidman}
\affiliation{
  \institution{D13, Lund University, Sweden}            %% \institution is required
}
\email{dat13dli@student.lu.se}          %% \email is recommended


\begin{abstract}
Text of abstract \ldots.
\end{abstract}


\maketitle


\section{Introduction}

%Entity discovery and linking
\acrfull{edl} is the process of finding mentions of entities in a text and linking these entities to the corresponding entry in a knowledge base. Named Entity Recognition (NER) and Entity Linking (EL) are the primary constituent steps of this process and in this paper we will describe the mechanisms by which our system performs these steps, both as separate processes and as a unified process (EDL).

In this project we attempt to reproduce the results achieved by~\cite{YangThe2017} using the methods outlined in their paper. The goal is to investigate whether the results are reproducible and additionally to potentially add support for other languages, seeking similar performance.

Our course of action for developing this system has been to iteratively reproduce the parts of the model from \cite{YangThe2017}, evaluating the model and adding features in each step of the iteration.

More text here

%\textit{Something about reproducing the model in iterative steps, comparing the performance as more features and layers are added?}

\section{System Description}
\subsection{Mention Detection}
As a first step in our iteration we leverage readily existing features from GloVe and CoreNLP to evaluate baseline performance in a basic reconstruction of the network described in \cite{YangThe2017}. The GloVe dataset provides our model with pre-trained word embeddings and CoreNLP provides us with basic NER (Named Entity Recognition) and POS (Part of Speech) tagging.

In future iterations we intend to add character embeddings (as described in \cite{Lample2016NeuralRecognition}) to compensate for OOV (Out of Vocabulary) issues. Additionally, 

\subsection{BiLSTM-CRF Model}

\lipsum[4-10] %% Boilerplate text


\section{Evaluation}

\lipsum[11-13] %% Boilerplate text


\section{Related work}

\lipsum[14-15] %% Boilerplate text

\section{Conclusion}

\lipsum[16-17] %% Boilerplate text
    
%% Acknowledgments
\begin{acks}
Text of acknowledgments \ldots.
\end{acks}


%% Bibliography
\bibliography{references}



\end{document}